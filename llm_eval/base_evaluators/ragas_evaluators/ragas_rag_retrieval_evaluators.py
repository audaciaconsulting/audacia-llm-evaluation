from ragas.metrics import LLMContextPrecisionWithReference, NonLLMContextPrecisionWithReference, LLMContextRecall, \
    NonLLMContextRecall
from langchain.chat_models.base import BaseChatModel
from llm_eval.tools.model_tools import get_ragas_wrapped_azure_openai_llm
from llm_eval.base_evaluators.ragas_evaluators.ragas_base_evaluator import RagasBaseEvaluator


class RunLLMContextPrecisionWithReference(RagasBaseEvaluator):
    """
        Evaluation Class: RAG
        Evaluation Method: LLM
        Granularity: High

        Evaluator class for computing context precision of retrieved contexts using an LLM,
        with a reference answer (ground truth). The metric determines how well the retrieved
        contexts align with the reference answer, evaluating the RAG system's ability to
        rank relevant contexts higher.

        Args:
            user_input (str): The user query or input to evaluate.
            reference (str): The expected or reference answer to the user query.
            retrieved_contexts (list[str]): A list of contexts retrieved by the system
                that are intended to help answer the query.
            threshold (float): A floating-point threshold in the range [0.0, 1.0] used
                to determine pass/fail criteria for the metric.
            llm (BaseChatModel, optional): An optional LLM instance to use for evaluation.
                If not provided, a default Azure OpenAI model is used.
        """

    def __init__(self, user_input: str, reference: str, retrieved_contexts: list[str], threshold: float,
                 llm: BaseChatModel = None):
        llm = llm or get_ragas_wrapped_azure_openai_llm()
        super().__init__(
            sample_data={"user_input": user_input, "reference": reference, "retrieved_contexts": retrieved_contexts},
            threshold=threshold, ragas_metric=LLMContextPrecisionWithReference, ragas_metric_args={"llm": llm})


class RunNonLLMContextPrecisionWithReference(RagasBaseEvaluator):
    """
       Evaluation Class: RAG
       Evaluation Method: String Similarity
       Granularity: Low

       Evaluator class for computing context precision of retrieved contexts using a
       non-LLM similarity metric, with a reference set of contexts. The metric assesses
       how well the retrieved contexts align with the reference contexts by comparing
       them via a non-LLM distance measure (e.g., string similarity). It evaluates the
       RAG system’s ability to retrieve and rank relevant textual passages.

       Args:
           retrieved_contexts (str): The list of contexts retrieved by the RAG system.
           reference_contexts (str): The list of ground truth/reference contexts that
               should ideally be retrieved.
           threshold (float): A floating-point threshold in the range [0.0, 1.0] used
               to convert similarity scores to binary verdicts for precision evaluation.
       """

    def __init__(self, retrieved_contexts: str, reference_contexts: str, threshold: float):
        super().__init__(
            sample_data={"retrieved_contexts": retrieved_contexts, "reference_contexts": reference_contexts},
            threshold=threshold, ragas_metric=NonLLMContextPrecisionWithReference)


class RunLLMContextRecall(RagasBaseEvaluator):
    """
        Evaluation Class: RAG
        Evaluation Method: LLM
        Granularity: High

        Evaluator class for computing context recall using an LLM, based on how well the
        retrieved contexts support the information in the reference answer. The metric estimates
        recall by classifying whether each part of the reference answer is attributable to the
        retrieved context, measuring the RAG system’s ability to include all necessary supporting
        information.

        Args:
            user_input (str): The original user query being evaluated.
            response (str): The response generated by the RAG system.
            reference (str): The reference answer used for evaluating recall.
            retrieved_contexts (list[str]): A list of textual contexts retrieved by the system.
            threshold (float): A floating-point threshold in the range [0.0, 1.0] used to determine
                pass/fail criteria for the metric.
            llm (BaseChatModel, optional): An optional LLM instance used for performing classification.
                If not provided, a default Azure OpenAI model is used.
        """

    def __init__(self, user_input: str, response: str, reference: str, retrieved_contexts: list[str], threshold: float,
                 llm: BaseChatModel = None):
        llm = llm or get_ragas_wrapped_azure_openai_llm()
        super().__init__(
            sample_data={"user_input": user_input, "response": response, "reference": reference,
                         "retrieved_contexts": retrieved_contexts},
            threshold=threshold, ragas_metric=LLMContextRecall, ragas_metric_args={'llm': llm})


class RunNonLLMContextRecall(RagasBaseEvaluator):
    """
        Evaluation Class: RAG
        Evaluation Method: String similarity
        Granularity: High

        Evaluator class for computing context recall using a non-LLM similarity metric, based on how well
        the retrieved contexts cover the reference contexts. The metric estimates recall by checking whether
        each reference context is sufficiently matched by any of the retrieved contexts using a string similarity
        measure. It evaluates the RAG system’s ability to retrieve all relevant supporting content.

        Args:
            retrieved_contexts (list[str]): A list of contexts retrieved by the RAG system.
            reference_contexts (list[str]): A list of reference or ground truth contexts that should be covered
                by the retrieved contexts.
            threshold (float): A floating-point threshold in the range [0.0, 1.0] used to determine whether
                a retrieved-reference match is considered relevant for recall computation.
        """

    def __init__(self, retrieved_contexts: list[str], reference_contexts: list[str], threshold: float):
        super().__init__(
            sample_data={"retrieved_contexts": retrieved_contexts, "reference_contexts": reference_contexts},
            threshold=threshold, ragas_metric=NonLLMContextRecall)
