from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.llms import LangchainLLMWrapper
from ragas.metrics import Faithfulness, ResponseRelevancy

from llm_eval.model_tools import get_ragas_wrapped_azure_openai_llm, get_ragas_wrapped_azure_open_ai_embedding_model
from llm_eval.ragas_evaluators.ragas_base_evaluator import RagasBaseEvaluator


class RunFaithfulness(RagasBaseEvaluator):
    """
        Evaluation Class: RAG
        Evaluation Method: LLM
        Granularity: High

        Evaluator class for computing the faithfulness of a generated response
        in relation to the retrieved contexts using an LLM. The faithfulness metric
        assesses whether the generated statements derived from the modelâ€™s response
        can be logically inferred from the retrieved context passages, helping ensure
        the response does not hallucinate or introduce unsupported claims.

        Args:
            user_input (str): The user query or input that triggered the response.
            response (str): The actual response generated by the RAG system.
            retrieved_contexts (list[str]): A list of retrieved context passages
                used as evidence to generate the response.
            threshold (float): A threshold in the range [0.0, 1.0] representing
                the minimum score for the response to be considered faithful.
            llm (LangchainLLMWrapper, optional): A wrapped LLM instance for use
                in evaluating statement entailment. If not provided, a default
                Azure OpenAI LLM is used.
    """

    def __init__(self, user_input: str, response: str, retrieved_contexts: list[str], threshold: float,
                 llm: LangchainLLMWrapper = None):
        llm = llm or get_ragas_wrapped_azure_openai_llm()
        super().__init__(
            sample_data={"user_input": user_input, "response": response, "retrieved_contexts": retrieved_contexts},
            threshold=threshold, ragas_metric=Faithfulness, ragas_metric_args={"llm": llm})


class RunResponseRelevancy(RagasBaseEvaluator):
    """
        Evaluation Class: RAG
        Evaluation Method: LLM + Embeddings
        Granularity: High

        Evaluator class for assessing how well a generated response addresses the original
        user query. This hybrid metric uses an LLM to generate follow-up questions based on
        the response, then compares them to the original query using cosine similarity in
        embedding space. A high similarity indicates strong relevance; vague or off-topic
        questions lower the score. Responses marked as noncommittal are penalized. This
        evaluation is best suited for tasks where responses must stay focused and aligned to
        the question, such as in RAG systems, QA bots, and support assistants.

        Args:
            user_input (str): The original input question or prompt from the user.
            response (str): The generated response whose relevance is being evaluated.
            threshold (float): A threshold in the range [0.0, 1.0] determining the
                minimum acceptable relevancy score for a passing evaluation.
            llm (LangchainLLMWrapper, optional): An optional LLM instance used for
                generating follow-up questions based on the response content. If not
                provided, a default Azure OpenAI model is used.
            embeddings (LangchainEmbeddingsWrapper, optional): An optional embeddings
                model used for computing cosine similarity between generated and
                reference-aligned questions. If not provided, a default Azure OpenAI
                embedding model is used.
    """

    def __init__(self, user_input: str, response: str, threshold: float,
                 llm: LangchainLLMWrapper = None, embeddings: LangchainEmbeddingsWrapper = None):
        llm = llm or get_ragas_wrapped_azure_openai_llm()
        embeddings = embeddings or get_ragas_wrapped_azure_open_ai_embedding_model()
        super().__init__(
            sample_data={"user_input": user_input, "response": response},
            threshold=threshold, ragas_metric=ResponseRelevancy,
            ragas_metric_args={"llm": llm, "embeddings": embeddings})
