[project]
name = "audacia-llm-evaluation"
version = "0.1.1"
description = "A framework to evaluate LLMs in AI systems"
authors = [
    { name = "Chris Bentley", email = "chris.bentley@audacia.co.uk" },
    { name = "Alan Kerby", email = "alan.kerby@audacia.co.uk" },
    { name = "Liam Ward", email = "liam.ward@audacia.co.uk" }
]
readme = "README.md"
license = "MIT"
requires-python = ">=3.11"
dependencies = [
    "audacia-datasciencetools",
    "azure-ai-evaluation>=1.8.0",
    "azure-ai-projects>=1.0.0b11",
    "huggingface-hub>=0.33.0",
    "langchain-openai>=0.3.24",
    "promptflow>=1.18.1",
    "pytest>=8.4.1",
    "pytest-asyncio>=1.0.0",
    "python-dotenv>=1.1.0",
    "ragas>=0.2.15",
    "rapidfuzz>=3.13.0",
    "torch>=2.7.1",
    "transformers>=4.52.4",
]

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["."]
include = ["llm_eval*"]


[tool.pytest.ini_options]
addopts = "-s --log-cli-level=INFO"
log_cli = true
log_cli_level = "INFO"

[tool.uv.sources]
audacia-datasciencetools = { git = "https://github.com/audaciaconsulting/Audacia.DataScienceTools.git" }
